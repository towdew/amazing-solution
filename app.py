import os
import re
import streamlit as st
import numpy as np
import pandas as pd
from PIL import Image, ImageDraw, ImageFont

# ========= ìºì‹œ ë””ë ‰í† ë¦¬(ì“°ê¸° ê°€ëŠ¥í•œ ê²½ë¡œ) =========
BASE_DIR = os.getcwd()
CACHE_DIR = os.path.join(BASE_DIR, ".cache")
HF_DIR = os.path.join(CACHE_DIR, "hf")
TORCH_DIR = os.path.join(CACHE_DIR, "torch")
EASYOCR_DIR = os.path.join(CACHE_DIR, "easyocr")
for d in [CACHE_DIR, HF_DIR, TORCH_DIR, EASYOCR_DIR]:
    os.makedirs(d, exist_ok=True)

os.environ["HF_HOME"] = HF_DIR
os.environ["TORCH_HOME"] = TORCH_DIR
os.environ["TRANSFORMERS_CACHE"] = HF_DIR
os.environ["EASYOCR_MODULE_PATH"] = EASYOCR_DIR

# ========= í˜ì´ì§€ ì„¤ì • =========
st.set_page_config(page_title="ì´ë¯¸ì§€ ê¸°ë°˜ PDP ìë™í™”", layout="centered")
st.markdown("""
<style>
  .main .block-container { max-width: 1000px !important; margin: 0 auto !important; }
</style>
""", unsafe_allow_html=True)

st.title("ì´ë¯¸ì§€ ê¸°ë°˜ PDP ìƒì„± ìë™í™” ì†”ë£¨ì…˜")
st.write("âœ… App is up")  # ë¶€íŒ… í™•ì¸

# ========= ì§€ì—° ë¡œë“œ ìœ í‹¸ =========
def get_blip():
    """
    BLIP ëª¨ë¸ì„ ì²« ì‚¬ìš© ì‹œì—ë§Œ ë¡œë“œ (ì§€ì—° ë¡œë“œ).
    ë¬´ê±°ìš´ importì™€ ë‹¤ìš´ë¡œë“œë¥¼ í•¨ìˆ˜ ë‚´ë¶€ë¡œ ë„£ì–´ ë¶€íŒ… íƒ€ì„ì•„ì›ƒ ë°©ì§€.
    """
    if "blip_loaded" not in st.session_state:
        with st.spinner("BLIP ëª¨ë¸ ë¡œë“œ ì¤‘... (ìµœì´ˆ 3~8ë¶„ ì†Œìš”)"):
            # ë¬´ê±°ìš´ ëª¨ë“ˆ importë¥¼ ì—¬ê¸°ì„œ
            from transformers import BlipProcessor, BlipForConditionalGeneration
            proc = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
            mdl = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
            st.session_state["blip_processor"] = proc
            st.session_state["blip_model"] = mdl
            st.session_state["blip_loaded"] = True
    return st.session_state["blip_processor"], st.session_state["blip_model"]

def get_easyocr():
    """EasyOCRë¥¼ ì²« ì‚¬ìš© ì‹œì—ë§Œ ë¡œë“œ (ì§€ì—° ë¡œë“œ)."""
    if "easyocr_loaded" not in st.session_state:
        with st.spinner("EasyOCR ë¡œë“œ ì¤‘... (ìµœì´ˆ 1~3ë¶„ ì†Œìš”)"):
            import easyocr  # ì§€ì—° import
            reader = easyocr.Reader(['en'], gpu=False, model_storage_directory=EASYOCR_DIR)
            st.session_state["easyocr_reader"] = reader
            st.session_state["easyocr_loaded"] = True
    return st.session_state["easyocr_reader"]

# ========= ì—…ë¡œë“œ UI =========
uploaded = st.file_uploader("ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["png","jpg","jpeg"])
if not uploaded:
    st.info("ì´ë¯¸ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”")
    st.stop()

from PIL import Image
img = Image.open(uploaded).convert("RGB")

# ë¯¸ë¦¬ë³´ê¸°(ë¼ë²¨ 1 í‘œì‹œ)
annotated = img.copy()
draw = ImageDraw.Draw(annotated)
font = ImageFont.load_default()
draw.text((10, 10), "1", fill="red", font=font)
st.image(annotated, use_container_width=True)

# ========= ê¸°ëŠ¥ í•¨ìˆ˜ë“¤ =========
def extract_text_via_easyocr(pil_img):
    reader = get_easyocr()
    arr = np.array(pil_img)
    lines = reader.readtext(arr, detail=0, paragraph=True)
    return "\n".join(lines)

def generate_blip_caption(pil_img):
    # torchë„ ì§€ì—° import (ë¶€íŒ… ì‹œ ë©”ëª¨ë¦¬/ì‹œê°„ ì ˆì•½)
    import torch
    processor, blip_model = get_blip()
    device = "cuda" if torch.cuda.is_available() else "cpu"
    inputs = processor(images=pil_img, return_tensors="pt").to(device)
    blip_model.to(device)
    out = blip_model.generate(**inputs, max_length=50)
    return processor.decode(out[0], skip_special_tokens=True)

def make_alt_candidates(pil_img):
    base = generate_blip_caption(pil_img)
    cands = [base, f"{base} in a modern environment", f"LG product - {base}"]
    # ì¤‘ë³µ ì œê±° í›„ ìµœëŒ€ 3ê°œ
    uniq = []
    for c in cands:
        if c not in uniq:
            uniq.append(c)
        if len(uniq) == 3:
            break
    return uniq

COMPONENT_DEFS = {
    "ST0001": {"name": "Hero banner", "has_image": True},
    "ST0002": {"name": "Tab Anchor", "has_image": False},
    "ST0003": {"name": "Title", "has_image": False},
    "ST0013": {"name": "Side Image", "has_image": True},
    "ST0014": {"name": "Layered Text", "has_image": True},
}
CTA_KEYWORDS = [
    "learn more","shop now","buy now","see more","read more",
    "click here","get started","try now","explore","discover","buy it now"
]

def classify_elements(lines):
    extracted, cleaned = [], []
    for L in lines:
        line = L
        for kw in CTA_KEYWORDS:
            if kw in line.lower():
                extracted.append(kw)
                import re as _re
                line = _re.sub(rf"\b{kw}\b", "", line, flags=_re.IGNORECASE).strip()
        if line:
            cleaned.append(line)
    disclaimers = [l for l in cleaned if l.startswith("*")]
    body = [l for l in cleaned if not l.startswith("*")]
    ey = body.pop(0) if body and body[0].isupper() else ""
    hl = body.pop(0) if body else ""
    bc = "\n".join(body)
    return {"Eyebrow": ey, "Headline": hl, "Bodycopy": bc,
            "Disclaimer": "\n".join(disclaimers),
            "CTA": (extracted[0] if extracted else "")}

def recommend_components(classified, has_image=True):
    return [cid for cid, comp in COMPONENT_DEFS.items() if comp["has_image"] == has_image]

# ========= UI ë™ì‘ =========
col1, col2 = st.columns(2)
with col1:
    if st.button("ğŸ–¼ï¸ Alt Text ìƒì„±"):
        st.session_state["candidates"] = make_alt_candidates(img)

with col2:
    if st.button("ğŸš€ OCR ì‹¤í–‰ (EasyOCR)"):
        txt = extract_text_via_easyocr(img)
        lines = txt.split("\n")
        st.session_state["ocr_done"] = True
        st.session_state["ocr_text"] = txt
        st.session_state["classified"] = classify_elements(lines)
        st.session_state["recs"] = recommend_components(st.session_state["classified"])

# ê²°ê³¼ í‘œì‹œ
if "candidates" in st.session_state:
    choice = st.radio("Alt Text í›„ë³´ ì„ íƒ:", st.session_state["candidates"], key="alt_choice")
    st.subheader("ğŸ–¼ï¸ Selected Alt Text")
    st.code(choice)

if st.session_state.get("ocr_done"):
    st.subheader("ğŸ“‹ OCR ê²°ê³¼")
    st.text_area("", st.session_state["ocr_text"], height=200)
    st.subheader("ğŸ“‘ í…ìŠ¤íŠ¸ ë¶„ë¥˜ ê²°ê³¼")
    for k, v in st.session_state["classified"].items():
        st.markdown(f"**{k}:** {v or 'â€”'}")
    with st.expander("ğŸ§© ì»´í¬ë„ŒíŠ¸ ì¶”ì²œ"):
        recs = st.session_state["recs"]
        if recs:
            sel = st.selectbox("ì¶”ì²œëœ ì»´í¬ë„ŒíŠ¸ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:", recs,
                               format_func=lambda cid: f"{cid} â€“ {COMPONENT_DEFS[cid]['name']}")
            st.markdown(f"**Selected Component:** {sel} â€“ {COMPONENT_DEFS[sel]['name']}")
            st.session_state["selected_component"] = sel
        else:
            st.write("ì¶”ì²œí•  ì»´í¬ë„ŒíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    df = pd.DataFrame.from_dict(st.session_state["classified"], orient='index', columns=['Content'])
    csv = df.to_csv(encoding='utf-8-sig')
    st.download_button("ğŸ’¾ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ", data=csv, file_name="ocr_result.csv", mime="text/csv")

if st.session_state.get("ocr_done") and st.button("ğŸ“¤ PDPìƒì„±í•˜ê¸° (WCMìœ¼ë¡œ ì „ì†¡í•˜ê¸°)"):
    st.caption("â€» í•´ë‹¹ ê¸°ëŠ¥ì€ ê¸°íš ë‹¨ê³„ì˜ êµ¬í˜„ì´ë©° ì‹¤ì œ ì ìš©ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
